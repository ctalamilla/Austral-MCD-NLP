# README - Clasificaci√≥n Autom√°tica de Documentos del Bolet√≠n Oficial

## üóÇÔ∏è Descripci√≥n General
Este proyecto aborda un desaf√≠o de Procesamiento de Lenguaje Natural (NLP) aplicado a documentos administrativos del Estado. Su objetivo es automatizar la clasificaci√≥n tem√°tica de documentos publicados en boletines oficiales, permitiendo una b√∫squeda m√°s eficiente y una comprensi√≥n sem√°ntica de grandes vol√∫menes de texto. 

<img src="img/image.png" alt="boletines" width="600"/>

Para lograrlo, se integran t√©cnicas modernas de NLP con arquitecturas preentrenadas, embebido sem√°ntico y modelos de inferencia `zero-shot`.

El pipeline completo abarca desde la descarga de boletines oficiales hasta su clasificaci√≥n autom√°tica y posterior b√∫squeda sem√°ntica a trav√©s de preguntas en lenguaje natural.

---

## üìÅ Estructura del Proyecto
```
project_root/
‚îÇ
‚îú‚îÄ‚îÄ boletines.zip                  # Archivo original descargado desde Google Drive
‚îú‚îÄ‚îÄ boletines_extraidos/          # Carpeta donde se extraen los PDFs
‚îÇ   ‚îî‚îÄ‚îÄ Boletines/
‚îÇ       ‚îî‚îÄ‚îÄ boletines_2024/       # Contiene todos los PDFs individuales
‚îú‚îÄ‚îÄ classification_checkpoint_*.pkl # Checkpoints peri√≥dicos durante la clasificaci√≥n
‚îú‚îÄ‚îÄ resumen.csv                   # Archivo CSV con los resultados finales
‚îî‚îÄ‚îÄ Austral_Entrega_Final_NLP_Boletines.ipynb # Notebook principal
```

---

## üîÅ Diagrama de Flujo del Proceso

```
graph TD
    A[Inicio] --> B[Descarga de PDF desde Drive]
    B --> C[Extracci√≥n de documentos con expresiones regulares]
    C --> D[Limpieza del texto (pies de p√°gina, encabezados)]
    D --> E[Creaci√≥n de DataFrame consolidado]
    E --> F[Clasificaci√≥n con modelo Zero-Shot]
    F --> G[An√°lisis y resumen de etiquetas]
    F --> H[Checkpoint y guardado]
    E --> I[Embeddings con SentenceTransformer]
    I --> J[√çndice FAISS para b√∫squeda]
    J --> K[B√∫squeda sem√°ntica por similitud textual]
```

---

## ü§ñ Componentes de NLP y su Operaci√≥n

### 1. Preprocesamiento de Documentos
Se descargan PDFs desde un enlace de Google Drive, se extrae su texto ignorando las primeras p√°ginas (√≠ndices) y se segmenta cada bolet√≠n en documentos individuales. La segmentaci√≥n se realiza utilizando expresiones regulares que detectan patrones como `OP N¬∫: XXXXXXX`, caracter√≠sticos de los boletines oficiales.

<img src="img/image3.png" alt="boletines" width="600"/>

<img src="img/image6.png" alt="boletines" width="600"/>


Posteriormente se eliminan encabezados y pies de p√°gina que interfieren en el an√°lisis sem√°ntico.

<img src="img/image7.png" alt="boletines" width="600"/>

### 2. Modelos de Clasificaci√≥n Zero-Shot
Utilizamos el modelo `facebook/bart-large-mnli`, entrenado en tareas de inferencia textual (NLI), que permite aplicar una t√©cnica denominada **zero-shot learning**. En lugar de requerir datos etiquetados para entrenamiento, el modelo puede inferir a qu√© categor√≠a pertenece un texto usando hip√≥tesis sem√°nticas del tipo:

> "Este documento trata sobre licitaciones p√∫blicas."

Se compara la probabilidad de esta hip√≥tesis para m√∫ltiples etiquetas candidatas.

<img src="img/image2.png" alt="boletines" width="600"/>

### 3. Clasificador Optimizado
Se implementa una clase `DocumentClassifierOptimized` que permite:
- Preprocesamiento por lotes.
- Clasificaci√≥n eficiente con reducci√≥n de memoria.
- Checkpoints peri√≥dicos para no perder el progreso.

Este enfoque resulta fundamental cuando se trabaja con m√°s de 15.000 documentos y se requiere procesamiento en GPU con eficiencia.

Finalmente se logra la prediccion del score de las etiquetas candidatas y se selecciona la etiqueta con mejor score.
<img src="img/image4.png" alt="boletines" width="300"/>
<img src="img/image5.png" alt="boletines" width="600"/>
### 4. B√∫squeda Sem√°ntica por Pregunta
Se integra un sistema de recuperaci√≥n de informaci√≥n basado en embeddings sem√°nticos:
- Se usa `SentenceTransformer` para representar cada documento como un vector en un espacio sem√°ntico.
- Se indexan estos vectores con `FAISS` para realizar consultas r√°pidas por distancia coseno o L2.
- Se ingresa una pregunta en lenguaje natural (ej: "¬øQu√© documentos mencionan adjudicaciones?") y el sistema devuelve los documentos m√°s relevantes.

Este componente transforma una b√∫squeda tradicional en una b√∫squeda inteligente, capaz de encontrar documentos aun cuando no contienen literalmente las palabras de la pregunta.

---

## üß† ¬øQu√© es Zero-Shot Learning y por qu√© es √∫til?
Zero-shot learning permite clasificar texto sin necesidad de entrenamiento adicional. Funciona mediante la evaluaci√≥n de la relaci√≥n sem√°ntica entre el texto de entrada y una lista de hip√≥tesis etiquetadas. En nuestro caso, las hip√≥tesis fueron dise√±adas en espa√±ol para reflejar categor√≠as t√≠picas de los boletines oficiales:

- "Este documento trata sobre leyes."
- "Este documento trata sobre resoluciones ministeriales."

La ventaja de este enfoque es que no se requiere un dataset previamente etiquetado. Se puede aplicar a nuevos dominios (como documentos administrativos) sin necesidad de fine-tuning.

---

## üìä Etiquetas Utilizadas
Las 19 etiquetas sem√°nticas definidas incluyen:
- Leyes
- Decisiones Administrativas
- Resoluciones Ministeriales
- Licitaciones P√∫blicas
- Contrataciones Abreviadas
- Sentencias
- Edictos Judiciales
- Recaudaci√≥n
- etc.

Estas categor√≠as permiten una clasificaci√≥n tem√°tica detallada y √∫til para tareas legales, administrativas y de transparencia.

---

## üåê Tecnolog√≠as Usadas
- **Python 3.11**
- **Hugging Face Transformers**
- **PyMuPDF (fitz)** para extracci√≥n de texto de PDF
- **pandas**, **numpy**, **tqdm** para manipulaci√≥n y visualizaci√≥n
- **sentence-transformers** para embeddings
- **FAISS** para b√∫squeda eficiente
- **Google Colab** para entrenamiento en GPU

---

## üìú Ejemplo de Uso
```python
pregunta = "¬øQu√© documentos mencionan edictos?"
resultados, indices = buscar_respuesta(pregunta)
```
Esto devuelve los documentos que, sem√°nticamente, se relacionan con adjudicaciones, aunque no contengan la palabra literal.

<img src="img/image10.png" alt="boletines" width="600"/>
---

## üöÄ Resultados
- Se procesaron **+15.000 documentos** extra√≠dos desde PDFs del bolet√≠n oficial.
- Se clasificaron en **19 categor√≠as** sin entrenamiento supervisado.
- Se gener√≥ un sistema de b√∫squeda inteligente capaz de responder preguntas.
- Se logr√≥ un pipeline automatizado, reproducible y escalable para tareas administrativas y legales.

---

## üìÑ Autor
Trabajo final de la materia **Text Mining**, Universidad Austral.

**Alberto Tejerina**
**Cristian Salinas**

---

## üîß Mejoras Futuras
- Entrenamiento supervisado con dataset etiquetado para aumentar la precisi√≥n.
- Incorporaci√≥n de OCR para textos escaneados (no seleccionables).
- Interfaz web de usuario para exploraci√≥n interactiva.
- Exportaci√≥n de resultados a bases de datos relacionales o APIs REST.

---

## ‚úÖ Evaluaci√≥n del Modelo de Clasificaci√≥n (Muestra Manual)

Se evalu√≥ el rendimiento del modelo sobre una muestra aleatoria de 68 documentos del Bolet√≠n Oficial, los cuales fueron etiquetados manualmente. Para garantizar una evaluaci√≥n justa, se eliminaron del an√°lisis aquellas **etiquetas verdaderas que el modelo nunca predijo**, ya que no formaban parte de las categor√≠as previstas.

### ‚ùå Etiquetas verdaderas no evaluables (no disponibles en el modelo)

```
ASAMBLEAS CIVILES
Avisos Comerciales
Avisos Generales
CONVOCATORIAS A AUDIENCIA P√öBLICA
DECRETOS
Decretos
EDICTOS DE MINAS
NOTIFICACIONES ADMINISTRATIVAS
POSESIONES VEINTEA√ëALES
REMATES JUDICIALES
```

Estas categor√≠as fueron eliminadas del c√°lculo de m√©tricas para no afectar negativamente al modelo con clases que no estaba dise√±ado para reconocer.

---

### üìä M√©tricas de Desempe√±o

Luego del filtrado, el modelo alcanz√≥ una **accuracy global de 96.1%**, con los siguientes resultados por clase:

```python
from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred))
```
<img src="img/image8.png" alt="boletines" width="600"/>

> üìå Pod√©s consultar el DataFrame `df_reporte` para ver la tabla completa en el notebook.

---

### üßÆ Matriz de Confusi√≥n

La siguiente matriz permite visualizar los aciertos (diagonal) y los errores de predicci√≥n (fuera de la diagonal):

```python
from sklearn.metrics import confusion_matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
```
<img src="img/image9.png" alt="boletines" width="600"/>
---

### üìå Conclusi√≥n

- El modelo demostr√≥ **alto rendimiento general** y buena capacidad de generalizaci√≥n, especialmente considerando que se trata de un sistema `zero-shot`.
- Las confusiones m√°s frecuentes se observaron entre etiquetas conceptualmente similares, como:
  - *Resoluciones Delegadas* ‚Üî *Resoluciones Ministeriales*
  - *Sentencias* ‚Üî *Edictos de Minas* (ambos tipos judiciales)
- La performance sugiere que el modelo es adecuado para tareas de clasificaci√≥n inicial y b√∫squeda inteligente en documentos administrativos.
